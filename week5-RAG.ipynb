{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04fa25cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain_community.document_loaders import UnstructuredWordDocumentLoader, UnstructuredFileLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d8166f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_documents(folder_path, file_extension):\n",
    "    documents = []\n",
    "    if file_extension == 'pdf':\n",
    "        pdf_loader = DirectoryLoader(folder_path, glob=\"./*.pdf\", loader_cls=PyPDFLoader)  # Select PDF files\n",
    "        documents += pdf_loader.load()\n",
    "    elif file_extension == 'txt':\n",
    "        txt_loader = DirectoryLoader(folder_path, glob=\"./*.txt\")  # Select TXT files\n",
    "        documents += txt_loader.load()\n",
    "    elif file_extension == 'docx':\n",
    "        docx_loader = DirectoryLoader(folder_path, glob=\"./*.docx\", loader_cls=UnstructuredWordDocumentLoader)\n",
    "        documents += docx_loader.load()\n",
    "    elif file_extension == 'combined':\n",
    "        pdf_loader = DirectoryLoader(folder_path, glob=\"./*.pdf\", loader_cls=PyPDFLoader)  # Select PDF files\n",
    "        documents += pdf_loader.load()\n",
    "        txt_loader = DirectoryLoader(folder_path, glob=\"./*.txt\")  # Select TXT files\n",
    "        documents += txt_loader.load()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d9ab98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = get_documents(\"C:\\\\Users\\\\vishi\\\\Downloads\\\\New folder\",\"docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bb0a5b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vishi\\Downloads\\New folder\\Dotnet Resume.docx\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].metadata[\"source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ecccb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1086, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divided into 62 chunks\n",
      "First chunk:\n",
      "\n",
      "page_content='Professional Summary\n",
      "\n",
      "I am full stack .Net Developer with 13+ years of experience in all the phases of Software development life cycle, which includes software analysis, design, development, testing, implementation, maintenance and documentation of Client/Server and Web-based applications using N-Tier Architecture. Experience in various domains like Banking, Finance and Insurance industries.\n",
      "\n",
      "Expertise on ASP.NET, C#, .NET, VB.NET, VB, Web API, LINQ, Entity Framework, .NET Core, MVC, ADO.NET, MS SQL Server, Restful API, Web API, Microservices.\n",
      "\n",
      "I am a professional skilled in Deployment, Bug fixes, Production support, and maintenance using tools such as Microsoft Visual Studio, JIRA, SVN, TFS, VSTS, Visual Studio Code etc.\n",
      "\n",
      "Efficient UI developer with efficient skills on Angular 2/4/6/8, Twitter Bootstrap, HTML, jQuery, HTML, HTML5, CSS, CSS3 JavaScript, Ajax, XML, JSON, Typescript with good hands on with browser side debugging and developer tools.' metadata={'source': 'C:\\\\Users\\\\vishi\\\\Downloads\\\\New folder\\\\Dotnet Resume.docx'}\n"
     ]
    }
   ],
   "source": [
    "#%pip install langchain-text-splitters\n",
    "\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# use text from the first loaded document\n",
    "#text = docs[0].page_content\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "chunks = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Divided into {len(chunks)} chunks\")\n",
    "print(f\"First chunk:\\n\\n{chunks[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4685784",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install sentence_transformers\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f828064",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chunks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m db_name=\u001b[33m\"\u001b[39m\u001b[33mresume_db\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m vectorstore = Chroma.from_documents(documents=\u001b[43mchunks\u001b[49m, embedding=embeddings, persist_directory=db_name)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mVectorstore created with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvectorstore._collection.count()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m documents\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'chunks' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "db_name=\"resume_db\"\n",
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_name)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17074ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load db if already created\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectorstore = Chroma(persist_directory=db_name, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9c01061",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a3a7cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "openrouter_api_key = \"sk-or-v1-fb3e8464dda71446faa8f7f7e659e2f0\"\n",
    "\n",
    "openrouter_url = \"https://openrouter.ai/api/v1\"\n",
    "llm = OpenAI(base_url=openrouter_url, api_key=openrouter_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd230fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_TEMPLATE = \"\"\"\n",
    "You are a HR person in a company who got multiple resume for the \n",
    "candidates. You are chatting with your manager.\n",
    "If relevant, use the given context to answer any question.\n",
    "If you don't know the answer, say so.\n",
    "Context:\n",
    "{context}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "de01ff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "def answer_question(question: str, history):\n",
    "    docs = retriever.invoke(question)\n",
    "    context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    system_prompt = SYSTEM_PROMPT_TEMPLATE.format(context=context)\n",
    "    #print(context)\n",
    "    response = llm.chat.completions.create(\n",
    "        model=\"mistralai/devstral-2512:free\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "44db6646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Touchrate Inc is located in Orlando, FL.\n"
     ]
    }
   ],
   "source": [
    "ans = answer_question(\"tell the state in which Touchrate Inc client is located\",[])\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb56cecb",
   "metadata": {},
   "source": [
    "# ADVANCED RAG INSTEAD OF INBUILT CHUNKING USE LLM TO CHUNK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0dd87df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "class Result(BaseModel):\n",
    "    page_content: str\n",
    "    metadata: dict\n",
    "\n",
    "    # A class to perfectly represent a chunk\n",
    "\n",
    "class Chunk(BaseModel):\n",
    "    headline: str = Field(description=\"A brief heading for this chunk, typically a few words, that is most likely to be surfaced in a query\")\n",
    "    summary: str = Field(description=\"A few sentences summarizing the content of this chunk to answer common questions\")\n",
    "    original_text: str = Field(description=\"The original text of this chunk from the provided document, exactly as is, not changed in any way\")\n",
    "\n",
    "    def as_result(self, document):\n",
    "        metadata = {\"source\": document.metadata[\"source\"]}\n",
    "        return Result(page_content=self.headline + \"\\n\\n\" + self.summary + \"\\n\\n\" + self.original_text,metadata=metadata)\n",
    "\n",
    "\n",
    "class Chunks(BaseModel):\n",
    "    chunks: list[Chunk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f801120",
   "metadata": {},
   "outputs": [],
   "source": [
    "AVERAGE_CHUNK_SIZE = 500\n",
    "def make_prompt(document):\n",
    "    how_many = (len(document.page_content) // AVERAGE_CHUNK_SIZE) + 1\n",
    "    return f\"\"\"\n",
    "You take a document and you split the document into overlapping chunks for a KnowledgeBase.\n",
    "\n",
    "The document is from the shared drive of a HR person.\n",
    "The document has been retrieved from: {document.metadata[\"source\"]}\n",
    "\n",
    "A chatbot will use these chunks to answer questions about the candidates experience and qualifications.\n",
    "You should divide up the document as you see fit, being sure that the entire document is returned in the chunks - don't leave anything out.\n",
    "This document should probably be split into {how_many} chunks, but you can have more or less as appropriate.\n",
    "There should be overlap between the chunks as appropriate; typically about 25% overlap or about 50 words, so you have the same text in multiple chunks for best retrieval results.\n",
    "\n",
    "For each chunk, you should provide a headline, a summary, and the original text of the chunk.\n",
    "Together your chunks should represent the entire document with overlap.\n",
    "\n",
    "Here is the document:\n",
    "\n",
    "{document.page_content}\n",
    "\n",
    "Respond with the chunks.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d35cfe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_messages(document):\n",
    "    return [\n",
    "        {\"role\": \"user\", \"content\": make_prompt(document)},\n",
    "    ]\n",
    "\n",
    "def process_document(document):\n",
    "    messages = make_messages(document)\n",
    "    response = llm.chat.completions.parse(\n",
    "        model=\"mistralai/devstral-2512:free\",\n",
    "        messages=messages, response_format=Chunks\n",
    "    )\n",
    "    reply = response.choices[0].message.content\n",
    "    doc_as_chunks = Chunks.model_validate_json(reply).chunks\n",
    "    return [chunk.as_result(document) for chunk in doc_as_chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "aa1134ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [02:32<00:00, 50.71s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def create_chunks(documents):\n",
    "    chunks = []\n",
    "    for doc in tqdm(documents):\n",
    "        chunks.extend(process_document(doc))\n",
    "    return chunks\n",
    "\n",
    "chunks = create_chunks(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ac56e0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Professional Summary Overview\\n\\nThe candidate is a full stack .Net Developer with over 13 years of experience in various phases of the software development life cycle, including analysis, design, development, testing, and maintenance. They have expertise in multiple domains such as Banking, Finance, and Insurance.\\n\\nProfessional Summary\\n\\nI am full stack .Net Developer with 13+ years of experience in all the phases of Software development life cycle, which includes software analysis, design, development, testing, implementation, maintenance and documentation of Client/Server and Web-based applications using N-Tier Architecture. Experience in various domains like Banking, Finance and Insurance industries.' metadata={'source': 'C:\\\\Users\\\\vishi\\\\Downloads\\\\New folder\\\\Dotnet Resume.docx'}\n"
     ]
    }
   ],
   "source": [
    "print(chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c1995eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb import PersistentClient\n",
    "collection_name = \"docs\"\n",
    "\n",
    "def create_embeddings(chunks):\n",
    "    chroma = PersistentClient(path=\"advancedRAG\")\n",
    "    if collection_name in [c.name for c in chroma.list_collections()]:\n",
    "        chroma.delete_collection(collection_name)\n",
    "\n",
    "    texts = [chunk.page_content for chunk in chunks]\n",
    "    emb = embeddings.embed_documents(texts)\n",
    "    emb = [type('obj', (object,), {'embedding': e})() for e in emb]\n",
    "    vectors = [e.embedding for e in emb]\n",
    "\n",
    "    collection = chroma.get_or_create_collection(collection_name)\n",
    "\n",
    "    ids = [str(i) for i in range(len(chunks))]\n",
    "    metas = [chunk.metadata for chunk in chunks]\n",
    "\n",
    "    collection.add(ids=ids, embeddings=vectors, documents=texts, metadatas=metas)\n",
    "    print(f\"Vectorstore created with {collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "334bb149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore created with 77 documents\n"
     ]
    }
   ],
   "source": [
    "create_embeddings(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9787067",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankOrder(BaseModel):\n",
    "    order: list[int] = Field(\n",
    "        description=\"The order of relevance of chunks, from most relevant to least relevant, by chunk id number\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f1cd672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank(question, chunks):\n",
    "    system_prompt = \"\"\"\n",
    "You are a document re-ranker.\n",
    "You are provided with a question and a list of relevant chunks of text from a query of a knowledge base.\n",
    "The chunks are provided in the order they were retrieved; this should be approximately ordered by relevance, but you may be able to improve on that.\n",
    "You must rank order the provided chunks by relevance to the question, with the most relevant chunk first.\n",
    "Reply only with the list of ranked chunk ids, nothing else. Include all the chunk ids you are provided with, reranked.\n",
    "\"\"\"\n",
    "    user_prompt = f\"The user has asked the following question:\\n\\n{question}\\n\\nOrder all the chunks of text by relevance to the question, from most relevant to least relevant. Include all the chunk ids you are provided with, reranked.\\n\\n\"\n",
    "    user_prompt += \"Here are the chunks:\\n\\n\"\n",
    "    for index, chunk in enumerate(chunks):\n",
    "        user_prompt += f\"# CHUNK ID: {index + 1}:\\n\\n{chunk.page_content}\\n\\n\"\n",
    "    user_prompt += \"Reply only with the list of ranked chunk ids, nothing else.\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ]\n",
    "    response = llm.chat.completions.parse(\n",
    "        model=\"mistralai/devstral-2512:free\",\n",
    "        messages=messages, response_format=RankOrder\n",
    "    )\n",
    "    #response = completion(model=MODEL, messages=messages, response_format=RankOrder)\n",
    "    reply = response.choices[0].message.content\n",
    "    order = RankOrder.model_validate_json(reply).order\n",
    "    print(order)\n",
    "    return [chunks[i - 1] for i in order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4ce7a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb import PersistentClient\n",
    "collection_name = \"docs\"\n",
    "RETRIEVAL_K = 10\n",
    "chroma = PersistentClient(path=\"advancedRAG\")\n",
    "collection = chroma.get_or_create_collection(collection_name)\n",
    "\n",
    "\n",
    "\n",
    "def fetch_context_unranked(question):\n",
    "    query = embeddings.embed_query(question)\n",
    "    results = collection.query(query_embeddings=[query], n_results=RETRIEVAL_K)\n",
    "    chunks = []\n",
    "    for result in zip(results[\"documents\"][0], results[\"metadatas\"][0]):\n",
    "        chunks.append(Result(page_content=result[0], metadata=result[1]))\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "93ebd4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education Backg...\n",
      "Rohith Kumar - ...\n",
      "Technical Skill...\n",
      "Jayam Solutions...\n",
      "Technical Skill...\n",
      "Security and Da...\n",
      "First Data Expe...\n",
      "Development and...\n",
      "DRS IT Groups E...\n",
      "H&R Block Exper...\n"
     ]
    }
   ],
   "source": [
    "question = \"Who is Rohith?\"\n",
    "chunks = fetch_context_unranked(question)\n",
    "\n",
    "for chunk in chunks:\n",
    "    print(chunk.page_content[:15]+\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8a8ded74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1, 3, 5, 6, 7, 4, 9, 10, 8]\n"
     ]
    }
   ],
   "source": [
    "reranked = rerank(question, chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0133859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_context(question):\n",
    "    chunks = fetch_context_unranked(question)\n",
    "    return rerank(question, chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9393b17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the context, include the source of the chunk\n",
    "\n",
    "def make_rag_messages(question, history, chunks):\n",
    "    context = \"\\n\\n\".join(f\"Extract from {chunk.metadata['source']}:\\n{chunk.page_content}\" for chunk in chunks)\n",
    "    system_prompt = SYSTEM_PROMPT_TEMPLATE.format(context=context)\n",
    "    return [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": question}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e378863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question: str, history: list[dict] = []) -> tuple[str, list]:\n",
    "    \"\"\"\n",
    "    Answer a question using RAG and return the answer and the retrieved context\n",
    "    \"\"\"\n",
    "    #query = rewrite_query(question, history), we can also improve the query using LLM\n",
    "    query = question\n",
    "    print(query)\n",
    "    chunks = fetch_context(query)\n",
    "    messages = make_rag_messages(question, history, chunks)\n",
    "    #response = completion(model=MODEL, messages=messages)\n",
    "    response = llm.chat.completions.create(\n",
    "        model=\"mistralai/devstral-2512:free\",\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content, chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbd5941a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did varun work for UPS client?\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "('Yes, Varun Nerella worked for **UPS** as a **Sr Systems Programmer Tech/.Net Full Stack Developer** from **March 2022 to Present** in **Charlotte, NC**.\\n\\nWould you like more details on his role or achievements there?', [Result(page_content='Professional Experience at UPS\\n\\nThe candidate worked as a Sr Systems Programmer Tech/.Net Full Stack Developer at UPS, focusing on full-stack development and modernization.\\n\\nUPS - Charlotte, NC | March 2022 - Present\\n\\nSr Systems Programmer Tech/ .Net Full Stack Developer\\n\\nFull-Stack Development: Built web applications using ASP.NET MVC/Core, C#, Angular20/19/17, React 19/18, Blazor, and HTML/CSS with responsive UI design.\\n\\nImplemented Native AOT (Ahead-of-Time compilation) in .NET 8 to create self-contained, optimized executables with faster startup times and reduced memory footprint.', metadata={'source': 'C:\\\\Users\\\\vishi\\\\Downloads\\\\New folder\\\\Varun Nerella .Net resume.docx'}), Result(page_content='API and Database Expertise at UPS\\n\\nThe candidate created RESTful APIs and worked with various databases at UPS.\\n\\nAPI Development: Created RESTful APIs with ASP.NET Web API and Spring, tested with tools like Fiddler, and integrated them with front-end components.\\n\\nDatabase Expertise: Worked with Oracle PL/SQL, SQL Server, and DynamoDB; developed stored procedures, triggers, and optimized queries for performance.', metadata={'source': 'C:\\\\Users\\\\vishi\\\\Downloads\\\\New folder\\\\Varun Nerella .Net resume.docx'}), Result(page_content='Key Achievements at UPS\\n\\nThe candidate enhanced application performance and scalability through full-stack development and UI modernization at UPS.\\n\\nKey Achievements:\\n\\nEnhanced Application Performance & Scalability by Full-Stack Development & UI Modernization\\n\\nRefactored Blazor-based UI to Angular for improved performance and compatibility.', metadata={'source': 'C:\\\\Users\\\\vishi\\\\Downloads\\\\New folder\\\\Varun Nerella .Net resume.docx'}), Result(page_content='Agile and UI/UX at UPS\\n\\nThe candidate participated in Agile ceremonies and developed reusable UI components at UPS.\\n\\nAgile & SDLC: Participated in Agile Scrum ceremonies, contributed to SDLC phases, and collaborated with BAs and QA teams. Demonstrated completed sprint features to business stakeholders during Sprint Review, collecting feedback and aligning on release readiness.\\n\\nUI/UX & Front-End: Created reusable UI components with Bootstrap, Kendo UI, React-Bootstrap, and Angular20/19/17; implemented client-side validations and SPA frameworks.', metadata={'source': 'C:\\\\Users\\\\vishi\\\\Downloads\\\\New folder\\\\Varun Nerella .Net resume.docx'}), Result(page_content='Security and AI Integration at UPS\\n\\nThe candidate secured service-to-service calls and integrated AI/ML models into .NET applications at UPS.\\n\\nSecured service-to-service calls with IAM using client-credentials and On-Behalf-Of (OBO) flows; propagated user claims through downstream .NET APIs with JWT validation, scope checks, and token replay defenses.\\n\\nIntegrated AI/ML models into .NET applications using ML.NET and TensorFlow.NET, enabling predictive analytics (e.g., forecasting, anomaly detection, recommendation systems).', metadata={'source': 'C:\\\\Users\\\\vishi\\\\Downloads\\\\New folder\\\\Varun Nerella .Net resume.docx'}), Result(page_content='Modernization at UPS\\n\\nThe candidate modernized a multi-module enterprise app at UPS, improving performance and deployment automation.\\n\\nModernized a multi-module enterprise app (policy/billing/quoting) by rewriting critical services from ASP.NET MVC 4/WebForms + WCF into .NET 6 Web APIs, improving performance, maintainability, and deployment automation.\\n\\nReplaced outdated libraries with modern equivalents (e.g., Newtonsoft → System.Text. Json, MSMQ/WCF → REST/SQS).', metadata={'source': 'C:\\\\Users\\\\vishi\\\\Downloads\\\\New folder\\\\Varun Nerella .Net resume.docx'}), Result(page_content='Role at American Express Serve\\n\\nThe candidate worked as a Sr .NET Applications Developer and DevOps Engineer at American Express Serve, involved in NUnit testing and system testing.\\n\\nClient: American Express Serve – St Petersburg, FL Apr 2014 – Apr 2017 Sr .NET Applications Developer and DevOps Engineer.\\n\\nInvolved in NUnit testing, system testing for code behind under MVC framework, and executed the regression cases using an automation framework. fine-tuning of System Center Orchestrator. This includes several complex runbooks which trigger PowerShell-based scripts and .NET APIs along with external services.', metadata={'source': 'C:\\\\Users\\\\vishi\\\\Downloads\\\\New folder\\\\Dotnet Resume.docx'}), Result(page_content='Professional Experience at NISI\\n\\nThe candidate worked as a .Net Developer at NISI, focusing on ASP.NET Web Forms and RESTful APIs.\\n\\nNISI - Hyderabad, India | May 2015 - July 2017\\n\\n.Net Developer\\n\\nASP.NET Web Forms, C#, JavaScript: Developed web applications using ASP.NET Web Forms, C#, and JavaScript for UI validation and mortgage rate tools.\\n\\nImplemented RESTful APIs to facilitate seamless data exchange between Alfresco and .NET-based applications, improving operational efficiency.', metadata={'source': 'C:\\\\Users\\\\vishi\\\\Downloads\\\\New folder\\\\Varun Nerella .Net resume.docx'}), Result(page_content='Professional Experience at SunTrust\\n\\nThe candidate worked as a Senior .Net Full Stack Developer at SunTrust, focusing on full-stack development and IAM.\\n\\nSunTrust - Atalanta, GA | May 2020 – February 2022\\n\\nSenior .Net Full Stack Developer\\n\\nFull-Stack Development: Built and maintained web applications using ASP.NET (VB.NET/C#), Angular, ReactJS, Blazor, HTML5, CSS3, Bootstrap, JavaScript, and TypeScript.\\n\\nBackend & API Development: Designed RESTful APIs and web services using ASP.NET Web API, Node.js, Spring Boot, WCF, and gRPC; used JSON extensively for data exchange.', metadata={'source': 'C:\\\\Users\\\\vishi\\\\Downloads\\\\New folder\\\\Varun Nerella .Net resume.docx'}), Result(page_content='Front-End and Security at NISI\\n\\nThe candidate designed prototypes and implemented role-based security at NISI.\\n\\nHTML, CSS, JavaScript: Designed and built prototypes using HTML, CSS, and JavaScript for responsive front-end interfaces.\\n\\nSSRS (SQL Server Reporting Services): Implemented role-based security in SSRS to manage access to reports and data.', metadata={'source': 'C:\\\\Users\\\\vishi\\\\Downloads\\\\New folder\\\\Varun Nerella .Net resume.docx'})])\n"
     ]
    }
   ],
   "source": [
    "ans = answer_question(\"Did varun work for UPS client?\",[])\n",
    "print(ans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
